# Scraper SEFAZ-MS

Este projeto cont√©m um scraper para extrair informa√ß√µes de servi√ßos do cat√°logo da Secretaria de Estado de Fazenda de Mato Grosso do Sul (SEFAZ-MS).

## üéØ Funcionalidades

- **Extra√ß√£o de dados estruturados**: Coleta categorias, perfis, servi√ßos e URLs
- **Detec√ß√£o autom√°tica de perfil**: Extrai o perfil da URL (ex: Agropecu√°ria, Com√©rcio)
- **Suporte √† pagina√ß√£o**: Processa automaticamente todas as p√°ginas dispon√≠veis
- **Constru√ß√£o completa de URLs**: Converte links relativos em URLs absolutas
- **Formata√ß√£o CSV otimizada**: Remove v√≠rgulas das categorias para evitar quebras no CSV
- **Rate limiting**: Pausa de 1 segundo entre requisi√ß√µes para respeitar o servidor
- **Logging detalhado**: Acompanhamento completo do processo de scraping
- **Tratamento de erros**: Gerenciamento robusto de falhas de conex√£o e parsing

## Estrutura do Projeto

```
‚îú‚îÄ‚îÄ sefaz_scraper.py    # Script principal do scraper
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md          # Este arquivo
‚îî‚îÄ‚îÄ sefaz_servicos.csv # Arquivo de sa√≠da (gerado ap√≥s execu√ß√£o)
```

## Instala√ß√£o

1. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

## Uso

### Execu√ß√£o B√°sica

Para executar o scraper com a URL padr√£o:

```bash
python sefaz_scraper.py
```

### Adicionando Novas URLs

Para fazer scraping de m√∫ltiplas p√°ginas, edite a lista `urls_to_scrape` na fun√ß√£o `main()` do arquivo `sefaz_scraper.py`:

```python
urls_to_scrape = [
    "https://www.catalogo.sefaz.ms.gov.br/Geral/agropecuaria/autorizacoes-cap/",
    "https://www.catalogo.sefaz.ms.gov.br/Geral/ccis-industria-e-servicos/autorizacoes-ccis/",
    # Adicione mais URLs aqui
]
```

## üìä Estrutura do CSV

O arquivo CSV gerado cont√©m as seguintes colunas:

| Coluna | Descri√ß√£o | Exemplo |
|--------|-----------|----------|
| **Categorias** | Categorias extra√≠das da div categorias, separadas por `;` | "Agropecu√°ria;Autoriza√ß√µes - CAP;Com√©rcio Ind√∫stria e Servi√ßos" |
| **Perfis** | Perfil extra√≠do da URL ou h1 | "Agropecu√°ria" |
| **Servi√ßos** | Nome do servi√ßo | "Autoriza√ß√£o espec√≠fica ‚Äì ICMS" |
| **URL** | URL completa do servi√ßo | "https://www.catalogo.sefaz.ms.gov.br/..." |

### Exemplo de dados:
```csv
Categorias,Perfis,Servi√ßos,URL
"Agropecu√°ria;Autoriza√ß√µes - CAP",Agropecu√°ria,"Autoriza√ß√£o espec√≠fica ‚Äì diferimento do ICMS",https://www.catalogo.sefaz.ms.gov.br/...
```

### Estrutura HTML Esperada

O scraper foi desenvolvido para trabalhar com a seguinte estrutura HTML:

```html
<!-- Categoria principal (usado como fallback para perfil) -->
<h1 class="green">Nome da Categoria</h1>

<!-- Servi√ßos -->
<div class="card-body">
    <a href="/link-do-servico">
        <h5 class="card-title">Nome do Servi√ßo</h5>
    </a>
    
    <!-- Categorias (extra√≠das para coluna Categorias) -->
    <div class="categorias mt-2">
        <a rel="category tag" href="#">Categoria 1</a>
        <a rel="category tag" href="#">Categoria 2</a>
    </div>
</div>

<!-- Pagina√ß√£o (processada automaticamente) -->
<div class="paginacao">
    <ul class="list-unstyled list-inline">
        <li><a href="/pagina-2">2</a></li>
        <li><a href="/pagina-3">3</a></li>
    </ul>
</div>
```

## üîß Caracter√≠sticas T√©cnicas

- **Detec√ß√£o de perfil inteligente**: Extrai perfil da URL automaticamente
- **Pagina√ß√£o autom√°tica**: Detecta e processa todas as p√°ginas dispon√≠veis
- **Preven√ß√£o de loops**: Sistema de controle de URLs visitadas
- **Formata√ß√£o CSV segura**: Remove v√≠rgulas das categorias para evitar quebras
- **Rate Limiting**: 1 segundo de pausa entre requisi√ß√µes
- **User-Agent**: Simula navegador real para evitar bloqueios
- **Encoding**: Suporte completo a UTF-8 para caracteres especiais
- **Error Handling**: Continua o scraping mesmo com falhas pontuais
- **Logging**: Registra todas as opera√ß√µes para debugging

## Logs

O scraper gera logs informativos durante a execu√ß√£o:
- In√≠cio do scraping de cada p√°gina
- Categoria principal encontrada
- N√∫mero de servi√ßos encontrados
- Total de registros salvos

## Manuten√ß√£o

### Adicionando Novos Seletores

Se a estrutura HTML mudar, voc√™ pode modificar os seletores nos seguintes m√©todos:

- `extract_category_from_h1()`: Para mudan√ßas no h1 da categoria
- `extract_service_data()`: Para mudan√ßas na estrutura dos cards
- `extract_profiles_from_categories()`: Para mudan√ßas na div de categorias

### Tratamento de Erros

O scraper inclui tratamento para:
- Falhas de conex√£o HTTP
- Elementos HTML n√£o encontrados
- Timeouts de requisi√ß√£o

## Depend√™ncias

- `requests`: Para fazer requisi√ß√µes HTTP
- `beautifulsoup4`: Para parsing HTML
- `csv`: Para gera√ß√£o do arquivo CSV (biblioteca padr√£o)
- `logging`: Para sistema de logs (biblioteca padr√£o)

## Limita√ß√µes

- O scraper funciona apenas com a estrutura HTML atual do site da SEFAZ-MS
- N√£o h√° suporte para JavaScript/conte√∫do din√¢mico
- Limitado a p√°ginas que seguem o padr√£o de cards identificado

## Contribui√ß√£o

Para contribuir com melhorias:
1. Identifique a mudan√ßa necess√°ria
2. Teste com diferentes URLs do cat√°logo SEFAZ-MS
3. Verifique se os logs est√£o informativos
4. Confirme que o CSV de sa√≠da mant√©m a estrutura esperada